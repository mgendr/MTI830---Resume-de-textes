{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35fa64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "import nltk\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "#import panda as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# Library for boxplots\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#from tensorflow.keras.layers import Attention\n",
    "#from attention import AttentionLayer\n",
    "\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616c5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path,filename):\n",
    "    json_obj_list=[]\n",
    "    with open(os.path.join(path,filename),'r') as fin:\n",
    "        for row in fin:\n",
    "            json_obj_list.append(json.loads(row))\n",
    "    return json_obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e08cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = {\n",
    "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
    "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
    "CURRENCY_REGEX = re.compile(\n",
    "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
    "\n",
    "EMAIL_REGEX = re.compile(\n",
    "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
    "    flags=re.IGNORECASE | re.UNICODE,)\n",
    "\n",
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    \n",
    "    text = text.lower()\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                print(\"contract\")\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "        \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = EMAIL_REGEX.sub(' ',text)\n",
    "    text = CURRENCY_REGEX.sub(' ',text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r\"'s\\b\",\"\", text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c49103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [01:12<00:00,  2.15it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A remplacer par \"train\"  \"val\"   \"test\"\n",
    "kind_data=\"test\"\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if file.endswith('.txt')]\n",
    "diff_abs,diff_des=[],[]\n",
    "for file_name in tqdm(file_names):\n",
    "    \n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    #print(listJSON)\n",
    "    #JSONlist=filterChars(os.path.join(\"data\",kind_data,\"g\"),file_name,listJSON)\n",
    "    for i in range(len(listJSON)) :\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        txt2_ab=clean_text(abstract, remove_stopwords = True)\n",
    "        if len(abstract)!=len(txt2_ab):\n",
    "            print(file_name, \", row \",i,\" abs-abs2 : \",len(abstract)-len(txt2_ab))\n",
    "        diff_abs.append(len(abstract)-len(txt2_ab))\n",
    "        txt2_de=clean_text(description, remove_stopwords = True)\n",
    "        if len(description)!=len(txt2_de):\n",
    "            print(file_name, \", row \",i,\" des-des2 : \",len(description)-len(txt2_de))\n",
    "        diff_des.append(len(description)-len(txt2_de))\n",
    "\n",
    "diff_abs,diff_des=np.array(diff_abs),np.array(diff_des)\n",
    "        \n",
    "sns.boxplot(data=diff_abs,fliersize=10)   \n",
    "plt.show()      \n",
    "sns.boxplot(data=diff_des,fliersize=10)   \n",
    "plt.show()      \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551b2d8",
   "metadata": {},
   "source": [
    "### Mesure des tailles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0dbf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:02<00:00, 64.43it/s]\n"
     ]
    }
   ],
   "source": [
    "abstract_word_count = []\n",
    "description_word_count = []\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for file_name in tqdm(file_names): \n",
    "\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    for i in range(len(listJSON)) :\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        \n",
    "        abstract_word_count.append(len(abstract.split()))\n",
    "        description_word_count.append(len(description.split()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01ebb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "length_df = pd.DataFrame({'descrition': description_word_count, 'abstract': abstract_word_count})\n",
    "length_df.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a8e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37456\n",
      "2074\n"
     ]
    }
   ],
   "source": [
    "print(max(description_word_count))\n",
    "print(max(abstract_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a1f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:02<00:00, 58.96it/s]\n"
     ]
    }
   ],
   "source": [
    "abstract_count = 0\n",
    "description_count = 0\n",
    "count=0\n",
    "lim_abs =160\n",
    "lim_des = 9000\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for file_name in tqdm(file_names): \n",
    "\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    for i in range(len(listJSON)) :\n",
    "        count+=1\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        \n",
    "        if(len(abstract.split())<=lim_abs):\n",
    "            abstract_count += 1\n",
    "        if(len(description.split())<=lim_des):\n",
    "            description_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e60d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nombre de description de taille inférieure à  9000  :  0.9957597664395941\n",
      " nombre d 'abstract de taille inférieure à  160  :  0.99673293479772\n",
      "14386\n"
     ]
    }
   ],
   "source": [
    "print(\" nombre de description de taille inférieure à \",lim_des , \" : \",description_count/count)    \n",
    "print(\" nombre d 'abstract de taille inférieure à \",lim_abs , \" : \",abstract_count/count)   \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27f0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dac8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6b663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7042b427",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69702eaf",
   "metadata": {},
   "source": [
    "## Sur Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a098ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [16:10<00:00,  6.26s/it]\n"
     ]
    }
   ],
   "source": [
    "kind_data=\"train\"\n",
    "\n",
    "x_tokenizer = Tokenizer() \n",
    "#x_tokenizer.fit_on_texts(_____)\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    descriptions = [i['description'] for i in listJSON  ]#listJSON[:]['description']\n",
    "    x_tokenizer.fit_on_texts(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e64b6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▍                                                            | 86359/588085 [00:00<00:01, 416743.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referring 367900\n",
      "fig 5199387\n",
      "service 309448\n",
      "technician 13298\n",
      "visiting 2887\n",
      "customer 210628\n",
      "location 405434\n",
      "provided 808434\n",
      "input 1283124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 588085/588085 [00:01<00:00, 383767.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 59.7163675319044 %\n",
      "Total Coverage of rare words: 0.11371321630587963 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in tqdm(x_tokenizer.word_counts.items()):\n",
    "    tot_cnt=tot_cnt+1\n",
    "    \n",
    "    tot_freq=tot_freq+value\n",
    "    if tot_cnt<10 :\n",
    "        print(key,value)\n",
    "    \n",
    "    \n",
    "    if(value<thresh):\n",
    "        \n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100,\"%\")\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407d8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 155/155 [1:19:10<00:00, 30.65s/it]\n"
     ]
    }
   ],
   "source": [
    "#prepare a LIMITED tokenizer for reviews on training data\n",
    "tokenizer_description = Tokenizer(num_words=tot_cnt-cnt) \n",
    "\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    descriptions = [i['description'] for i in listJSON  ]\n",
    "    tokenizer_description.fit_on_texts(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803e6ed",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c60920e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [02:35<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "#x_tokenizer.fit_on_texts(_____)\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    abstracts = [i['abstract'] for i in listJSON  ]#listJSON[:]['description']\n",
    "    x_tokenizer.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f41ae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 68948/68948 [00:00<00:00, 380128.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 47.82009630446134 %\n",
      "Total Coverage of rare words: 0.2959113934193723 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in tqdm(x_tokenizer.word_counts.items()):\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    \n",
    "    if(value<thresh):\n",
    "        \n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100,\"%\")\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac7fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [02:40<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "#prepare a LIMITED tokenizer for reviews on training label\n",
    "tokenizer_abstract = Tokenizer(num_words=tot_cnt-cnt) \n",
    "\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    abstracts = [i['abstract'] for i in listJSON  ]\n",
    "    tokenizer_abstract.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335956dd",
   "metadata": {},
   "source": [
    "## Save des token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eef3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenize_file(path,filename,JSONlist,tokenizer_x,tokenizer_y):\n",
    "    \n",
    "    if os.path.exists(path+'new_tok_'+filename+'.txt')==True:\n",
    "        os.remove(path+'new_tok_'+filename)\n",
    "        \n",
    "    descriptions = [i['description'] for i in JSONlist  ]\n",
    "    x_tr_seq   =  tokenizer_x.texts_to_sequences(descriptions)\n",
    "    \n",
    "    \n",
    "    \n",
    "    abstracts = [i['abstract'] for i in JSONlist  ]\n",
    "    y_tr_seq   =  tokenizer_y.texts_to_sequences(abstracts) \n",
    "    \n",
    "    #print(len(x_tr_seq))\n",
    "    #print(x_tr_seq)\n",
    "    \n",
    "    new_f= open(path+'new_tok'+filename,'a')\n",
    "  \n",
    "    for i in range(len(JSONlist)) :\n",
    "        #JSONlist[i]['abstract']=x_tr_seq[i]\n",
    "        #JSONlist[i]['description']=y_tr_seq[i]\n",
    "    \n",
    "        updatedJSON={\"publication_number\":JSONlist[i]['publication_number'],\"abstract\":x_tr_seq[i],\"description\":y_tr_seq[i]}\n",
    "        new_f.write(json.dumps(updatedJSON))\n",
    "        \n",
    "        \n",
    "    #print(\"Wrote file \"+new_f.name)\n",
    "    new_f.close()\n",
    "    \n",
    "    #f2= open(path+'new_tok'+filename,'r')\n",
    "    #text = f2.read().replace('}{\"publication_number\"','}\\n{\"publication_number\"').encode(\"utf8\")\n",
    "    \n",
    "    #f2.write(str(text))\n",
    "    #f2.close()\n",
    "    \n",
    "def addLineReturn(path,filename):\n",
    "    f=open(os.path.join(path,file_name2),'r')\n",
    "    text = f.read().replace('}{\"publication_number\"','}\\n{\"publication_number\"').encode(\"utf8\")\n",
    "    f.close()\n",
    "    f2=open(os.path.join(os.path.join(\"data\",kind_data,\"g\"),file_name2),'wb')\n",
    "    f2.write(text)\n",
    "    f2.close()\n",
    "    print(\"Updated file \"+f2.name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de98c8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [18:10<00:00,  7.04s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [01:00<00:00,  2.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [00:55<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Enregistrement des données tokénisés\n",
    "os.makedirs(\"data_token\", exist_ok=True)\n",
    "for kind_data in [\"train\",\"val\",\"test\"]:\n",
    "    name_folder0 = \"data_token/\"+kind_data\n",
    "    name_folder = \"data_token/\"+kind_data+\"/g\"\n",
    "    os.makedirs(name_folder0, exist_ok=True)\n",
    "    os.makedirs(name_folder, exist_ok=True)\n",
    "    \n",
    "    file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "    for i in tqdm(range(len(file_names))) :\n",
    "        file_name=file_names[i]\n",
    "        listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name) \n",
    "\n",
    "        \n",
    "        \n",
    "        #Padding ?????????????????????????????????????\n",
    "        #x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "        #x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "    \n",
    "        #on save ici le fichier à l'adresse\n",
    "        create_tokenize_file(name_folder+\"/\",file_name,listJSON,tokenizer_description,tokenizer_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c84d083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SAVE LES TOKENIZER\n",
    "##MEME TOKENIZER POUR X ET Y ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0084fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:07<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3867\n",
      "481\n",
      "[44, 1160, 40074, 1528, 1821, 7, 867, 303, 1078, 9, 151, 170, 900, 52, 21, 26, 441, 565, 31, 31, 25, 35, 167, 35, 82, 31, 2, 84, 1621, 2361, 3589, 88805, 1887, 1438, 1158, 21, 185, 63696, 2855, 174401, 278, 544, 104, 380, 84, 12517, 1530, 12517, 1530, 167, 6, 35, 82, 121, 380, 84, 170, 900, 170, 900, 2155, 82, 31, 25, 35, 82, 1530, 595, 1096, 5254, 900, 1743, 1814, 28, 1466, 132, 489, 6, 51, 31, 25, 35, 167, 88, 1814, 28, 1466, 132, 2584, 278, 1044, 47, 31, 62, 489, 222, 31, 25, 35, 519, 1044, 278, 25, 900, 519, 136, 278, 17, 808, 1466, 132, 123, 2889, 222, 25, 35, 1466, 132, 583, 104, 278, 1044, 47, 31, 2889, 222, 1031, 867, 1160, 2889, 222, 51, 1466, 132, 25, 35, 293, 121, 28, 1466, 132, 28, 121, 1466, 132, 163, 586, 28, 28, 35, 121, 1466, 132, 1466, 132, 1519, 2889, 222, 4, 2490, 5528, 15210, 847, 1577, 2889, 222, 1189, 222, 2, 762, 1088, 1375, 422, 6094, 222, 7278, 1015, 970, 2, 1541, 147, 4941, 31, 544, 104, 278, 166, 501, 7, 1151, 19970, 508, 3727, 128, 41, 31, 334, 314, 111, 163, 586, 28, 28, 35, 2, 15, 586, 80, 31, 112, 163, 586, 28, 121, 1466, 132, 1015, 970, 5545, 544, 678, 63, 80, 11712, 2158, 18, 544, 104, 278, 166, 82, 1530, 121, 1466, 132, 35, 82, 25, 35, 31, 3702, 228, 544, 2, 157, 3578, 82, 117, 41, 3600, 157, 508, 48, 157, 629, 603, 3793, 144, 470, 82, 48, 157, 629, 603, 144, 144, 52, 31, 35, 337, 31, 489, 6, 4169, 62, 508, 128, 31, 2857, 25, 1466, 132, 51, 201, 3578, 82, 351, 489, 6, 31, 3634, 434, 104, 278, 583, 3578, 82, 117, 470, 117, 157, 1407, 508, 48, 157, 629, 603, 3793, 144, 31, 2465, 155, 508, 278, 294, 252, 503, 3578, 117, 41, 6981, 24, 339, 1335, 159, 278, 939, 511, 339, 2306, 31, 20, 1752, 361, 73, 315, 160, 6981, 134, 1208, 339, 544, 277, 461, 278, 2, 205, 2465, 312, 511, 1528, 2410, 2229, 95, 7, 167, 2889, 489, 222, 583, 104, 278, 1044, 47, 31, 1015, 1388, 104, 278, 2792, 60, 199, 51, 1151, 19970, 508, 3727, 128, 31, 41, 1015, 1388, 51, 7426, 544, 31, 80, 11712, 2158, 18, 104, 278, 166, 3578, 82, 117, 508, 31, 128, 2857, 104, 82, 3578, 231, 31, 3634, 906, 104, 278, 3578, 117, 41, 339, 1335, 159, 278, 939, 511, 1444, 670, 4231, 1335, 169, 31, 2992, 418, 990, 2992, 1321, 849, 1528, 1821, 24, 25984, 328, 762, 1088, 35, 82, 334, 314, 111, 1812, 2959, 2204, 8544, 422, 82, 1049, 38, 1053, 340, 2347, 347, 159, 10, 7, 114, 24, 338, 4746, 334, 7, 202, 1278, 96, 289, 2, 19, 89, 384, 487, 537, 139, 760, 745, 234, 7, 334, 314, 111]\n",
      "1649\n",
      "1649\n"
     ]
    }
   ],
   "source": [
    "###### Du test\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",\"train\",\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names[0]))) : \n",
    "    file_name=file_names[i]\n",
    "\n",
    "    listJSON = readData(os.path.join(\"data\",\"train\",\"g\"),file_name)\n",
    "    descriptions = [i['description'] for i in listJSON  ]\n",
    "    abstracts = [i['abstract'] for i in listJSON  ]\n",
    "\n",
    "\n",
    "x_tr_seq   =  tokenizer_description.texts_to_sequences(descriptions)\n",
    "\n",
    "print(len(descriptions[0]))\n",
    "print(len(x_tr_seq[0]))\n",
    "print(x_tr_seq[0])\n",
    "\n",
    "print(len(x_tr_seq))\n",
    "print(len(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2a4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(tokenizer_description.get_config())\n",
    "print(tokenizer_abstract.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb4db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e80f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enregistrement du tokenizer\n",
    "path = \"data_token/\"\n",
    "\n",
    "Json_tok_ab = tokenizer_abstract.to_json()\n",
    "new_f_ab = open(path+'tokenizer_abstract.txt','a')\n",
    "new_f_ab.write(json.dumps(Json_tok_ab))\n",
    "new_f_ab.close()\n",
    "\n",
    "Json_tok_de = tokenizer_description.to_json()\n",
    "new_f_de = open(path+'tokenizer_description.txt','a')\n",
    "new_f_de.write(json.dumps(Json_tok_ab))\n",
    "new_f_de.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14e6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a90802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47deed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cef0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f61552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a41100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6d4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452de862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "676e0adf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f1867f5fdb64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#prepare a tokenizer for reviews on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_tr' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(x_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295e7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "sj_train_features_scaled = sj_train_features.copy()\n",
    "\n",
    "\n",
    "sj_train_features_scaled[sj_train_features_scaled.columns]= scaler.fit_transform(sj_train_features[sj_train_features.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_features_scaled['total_cases'] = sj_train_features['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27401add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized_torch = []\n",
    "for column in sj_train_features_scaled.columns:\n",
    "    train_data_normalized_torch.append(torch.FloatTensor(sj_train_features_scaled[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22961263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On test en selectionnant un certain nombre de features\n",
    "\n",
    "features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c','total_cases']\n",
    "\n",
    "train_data_selected_torch = [torch.FloatTensor(sj_train_features_scaled[feature]) for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc81e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw): #remplacer lim-1 par 20 si ça bug\n",
    "    inout_seq = []\n",
    "    L = len(input_data[0])\n",
    "    lim = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[0][i:i+tw].view(tw,1,-1)\n",
    "        for j in range(1,lim-1):\n",
    "            train_seq = torch.cat((train_seq,input_data[j][i:i+tw].view(tw,1,-1)),-1)\n",
    "\n",
    "        train_label = input_data[lim-1][i+tw]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inout_seq = create_inout_sequences(train_data_normalized_torch, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "inout_seq_selected = create_inout_sequences(train_data_selected_torch, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e016c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c521ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61374111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden_layer_size=150, output_size=1): #hidden_layer_size = 100\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq, self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out)\n",
    "        return predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5cba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5dbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "training_ratio = 0.8\n",
    "training_data = inout_seq[0:math.floor(training_ratio*len(inout_seq))]\n",
    "valid_data = inout_seq[math.floor(training_ratio*len(inout_seq)):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(inout_seq):\n",
    "    train_chouchou = [inout_seq[i] for i in train_index]\n",
    "    train_chouchou = [inout_seq[i] for i in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "training_loss=[]\n",
    "valid_loss=[]\n",
    "for train_index, test_index in kf.split(inout_seq):\n",
    "    training_data = [inout_seq[i] for i in train_index]\n",
    "    valid_data = [inout_seq[i] for i in test_index]\n",
    "    for i in range(epochs):\n",
    "        if i == 100:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for seq, labels in training_data:\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "            single_loss_r = loss_function(y_pred[0][0], labels)\n",
    "            single_loss_r.backward()\n",
    "            training_loss.append(single_loss_r.item())\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        for seq, labels in valid_data:\n",
    "            y_pred = model(seq)\n",
    "            running_loss = loss_function(y_pred[0][0], labels)\n",
    "            valid_loss.append(running_loss.item())\n",
    "\n",
    "        print(\"Epoch: \",i, \"__ Training Loss: \", training_loss[-1],\"__ Valid Loss:\", valid_loss[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae908f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28887760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
