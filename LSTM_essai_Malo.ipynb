{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828efb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Malo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "import nltk\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "#import panda as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# Library for boxplots\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "\n",
    "#from tensorflow.keras.layers import Attention\n",
    "#from attention import AttentionLayer\n",
    "\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5b167b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = {\n",
    "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
    "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
    "CURRENCY_REGEX = re.compile(\n",
    "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
    "\n",
    "EMAIL_REGEX = re.compile(\n",
    "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
    "    flags=re.IGNORECASE | re.UNICODE,)\n",
    "\n",
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    \n",
    "    text = text.lower()\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                print(\"contract\")\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "        \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = EMAIL_REGEX.sub(' ',text)\n",
    "    text = CURRENCY_REGEX.sub(' ',text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r\"'s\\b\",\"\", text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3600e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241\n",
      "methods and systems are provided for obtaining information related to a customer service location and directions for routing a service technician from one customer service location to another . one embodiment includes requesting at least one set of coordinates associated with the customer service location ; accessing a technician server to direct a global satellite positioning system to obtain the set of coordinates for the customer service location ; obtaining the coordinates and updating one or more databases with said coordinates . the coordinates may include at least one of a latitude and a longitude associated with the customer service location . another embodiment includes obtaining through a technician server at least one set of “ from ” coordinates associated with the first customer service location and at least one set of “ to ” coordinates associated with the second customer location ; transmitting the “ from ” and “ to ” coordinates to a mapping system ; and , generating directions in the mapping system based on the “ to ” and “ from ” coordinates . at least one of the sets of coordinates includes latitude and longitude data . system and computer - readable media embodiments of these methods are also provided .\n"
     ]
    }
   ],
   "source": [
    "# A remplacer par \"train\"  \"val\"   \"test\"\n",
    "kind_data=\"train\"\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" not in file]\n",
    "for file_name in file_names:\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    #JSONlist=filterChars(os.path.join(\"data\",kind_data,\"g\"),file_name,listJSON)\n",
    "    for i in range(len(listJSON)) :\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        #print(len(abstract))\n",
    "        #print(abstract)\n",
    "        txt2=clean_text(abstract, remove_stopwords = True)\n",
    "        \n",
    "        \n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e77c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957\n",
      "methods systems provided obtaining information related customer service location directions routing service technician one customer service location another one embodiment includes requesting least one set coordinates associated customer service location accessing technician server direct global satellite positioning system obtain set coordinates customer service location obtaining coordinates updating one databases said coordinates coordinates may include least one latitude longitude associated customer service location another embodiment includes obtaining technician server least one set “ ” coordinates associated first customer service location least one set “ ” coordinates associated second customer location transmitting “ ” “ ” coordinates mapping system generating directions mapping system based “ ” “ ” coordinates least one sets coordinates includes latitude longitude data system computer readable media embodiments methods also provided\n"
     ]
    }
   ],
   "source": [
    "print(len(txt2))\n",
    "print(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04792fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e2cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de564499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de26ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def readData(path,filename):\n",
    "    json_obj_list=[]\n",
    "    with open(os.path.join(path,filename),'r') as fin:\n",
    "        for row in fin:\n",
    "            json_obj_list.append(json.loads(row))\n",
    "    return json_obj_list\n",
    "\n",
    "\n",
    "def filterChars(path,filename,JSONlist):\n",
    "    cachedstopwords = stopwords.words(\"english\")\n",
    "    if os.path.exists(path+'new_'+filename+'.txt')==True:\n",
    "        os.remove(path+'new_'+filename+'.txt')\n",
    "    new_f= open(os.path.join(path,'new_'+filename)+'.txt','a')\n",
    "    for i in range(len(JSONlist)) :\n",
    "        abstract = JSONlist[i]['abstract']\n",
    "        description = JSONlist[i]['description']\n",
    "            \n",
    "        abstract1 = abstract.lower()\n",
    "        description1 = description.lower()\n",
    "            \n",
    "        abstract2 = re.sub('[^a-zA-Z ]',' ',abstract1)\n",
    "        description2 = re.sub('[^a-zA-Z ]',' ',description1)\n",
    "            \n",
    "        abstract3 = re.sub(r'(?:^| )\\w(?:$| )', ' ', abstract2).strip()\n",
    "        description3 = re.sub(r'(?:^| )\\w(?:$| )', ' ', description2).strip()\n",
    "            \n",
    "        abstract4 = ' '.join([word for word in abstract3.split() if word not in cachedstopwords])\n",
    "        description4 = ' '.join([word for word in description3.split() if word not in cachedstopwords])\n",
    "            \n",
    "        abstract5=re.sub(' +',' ',abstract4)\n",
    "        description5=re.sub(' +',' ',description4)\n",
    "            \n",
    "        JSONlist[i]['abstract']=abstract5\n",
    "        JSONlist[i]['description']=description5\n",
    "        updatedJSON={\"publication_number\":JSONlist[i]['publication_number'],\"abstract\":abstract5,\"description\":description5}\n",
    "        new_f.write(json.dumps(updatedJSON))\n",
    "    print(\"Wrote file \"+new_f.name)\n",
    "    new_f.close()\n",
    "    return JSONlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fc9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A remplacer par \"train\"  \"val\"   \"test\"\n",
    "kind_data=\"train\"\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for file_name in file_names:\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    #JSONlist=filterChars(os.path.join(\"data\",kind_data,\"g\"),file_name,listJSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
