{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a397f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\malog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "import nltk\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "#import panda as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# Library for boxplots\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#from tensorflow.keras.layers import Attention\n",
    "#from attention import AttentionLayer\n",
    "\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44426fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path,filename):\n",
    "    json_obj_list=[]\n",
    "    with open(os.path.join(path,filename),'r') as fin:\n",
    "        for row in fin:\n",
    "            json_obj_list.append(json.loads(row))\n",
    "    return json_obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff6bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = {\n",
    "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
    "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
    "CURRENCY_REGEX = re.compile(\n",
    "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
    "\n",
    "EMAIL_REGEX = re.compile(\n",
    "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
    "    flags=re.IGNORECASE | re.UNICODE,)\n",
    "\n",
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    \n",
    "    text = text.lower()\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                print(\"contract\")\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "        \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = EMAIL_REGEX.sub(' ',text)\n",
    "    text = CURRENCY_REGEX.sub(' ',text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r\"'s\\b\",\"\", text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea9df50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:31<00:00, 21.14s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A remplacer par \"train\"  \"val\"   \"test\"\n",
    "kind_data=\"train\"\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file][:10]\n",
    "diff_abs,diff_des=[],[]\n",
    "for file_name in tqdm(file_names):\n",
    "    \n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    #print(listJSON)\n",
    "    #JSONlist=filterChars(os.path.join(\"data\",kind_data,\"g\"),file_name,listJSON)\n",
    "    for i in range(len(listJSON)) :\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        txt2_ab=clean_text(abstract, remove_stopwords = True)\n",
    "        if len(abstract)!=len(txt2_ab):\n",
    "            print(file_name, \", row \",i,\" abs-abs2 : \",len(abstract)-len(txt2_ab))\n",
    "        diff_abs.append(len(abstract)-len(txt2_ab))\n",
    "        txt2_de=clean_text(description, remove_stopwords = True)\n",
    "        if len(description)!=len(txt2_de):\n",
    "            print(file_name, \", row \",i,\" des-des2 : \",len(description)-len(txt2_de))\n",
    "        diff_des.append(len(description)-len(txt2_de))\n",
    "\n",
    "diff_abs,diff_des=np.array(diff_abs),np.array(diff_des)\n",
    "        \n",
    "sns.boxplot(data=diff_abs,fliersize=10)   \n",
    "plt.show()      \n",
    "sns.boxplot(data=diff_des,fliersize=10)   \n",
    "plt.show()      \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5289ede",
   "metadata": {},
   "source": [
    "### Mesure des tailles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828625ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [03:01<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "abstract_word_count = []\n",
    "description_word_count = []\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for file_name in tqdm(file_names): \n",
    "\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    for i in range(len(listJSON)) :\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        \n",
    "        abstract_word_count.append(len(abstract.split()))\n",
    "        description_word_count.append(len(description.split()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2113883c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "length_df = pd.DataFrame({'descrition': description_word_count, 'abstract': abstract_word_count})\n",
    "length_df.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66eb2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37456\n",
      "2074\n"
     ]
    }
   ],
   "source": [
    "print(max(description_word_count))\n",
    "print(max(abstract_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab1fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [02:50<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "abstract_count = 0\n",
    "description_count = 0\n",
    "count=0\n",
    "lim_abs =160\n",
    "lim_des = 9000\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for file_name in tqdm(file_names): \n",
    "\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "    for i in range(len(listJSON)) :\n",
    "        count+=1\n",
    "        abstract = listJSON[i]['abstract']\n",
    "        description = listJSON[i]['description']\n",
    "        \n",
    "        if(len(abstract.split())<=lim_abs):\n",
    "            abstract_count += 1\n",
    "        if(len(description.split())<=lim_des):\n",
    "            description_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd06a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nombre de description de taille inférieure à  9000  :  0.99562438449804\n",
      " nombre d 'abstract de taille inférieure à  160  :  0.9963813312221214\n",
      "258935\n"
     ]
    }
   ],
   "source": [
    "print(\" nombre de description de taille inférieure à \",lim_des , \" : \",description_count/count)    \n",
    "print(\" nombre d 'abstract de taille inférieure à \",lim_abs , \" : \",abstract_count/count)   \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c23f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d78c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d426e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8d91048",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4204e22",
   "metadata": {},
   "source": [
    "## Sur Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7b4c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [16:10<00:00,  6.26s/it]\n"
     ]
    }
   ],
   "source": [
    "kind_data=\"train\"\n",
    "\n",
    "x_tokenizer = Tokenizer() \n",
    "#x_tokenizer.fit_on_texts(_____)\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    descriptions = [i['description'] for i in listJSON  ]#listJSON[:]['description']\n",
    "    x_tokenizer.fit_on_texts(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d6ba327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▍                                                            | 86359/588085 [00:00<00:01, 416743.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referring 367900\n",
      "fig 5199387\n",
      "service 309448\n",
      "technician 13298\n",
      "visiting 2887\n",
      "customer 210628\n",
      "location 405434\n",
      "provided 808434\n",
      "input 1283124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 588085/588085 [00:01<00:00, 383767.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 59.7163675319044 %\n",
      "Total Coverage of rare words: 0.11371321630587963 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in tqdm(x_tokenizer.word_counts.items()):\n",
    "    tot_cnt=tot_cnt+1\n",
    "    \n",
    "    tot_freq=tot_freq+value\n",
    "    if tot_cnt<10 :\n",
    "        print(key,value)\n",
    "    \n",
    "    \n",
    "    if(value<thresh):\n",
    "        \n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100,\"%\")\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57df22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 155/155 [1:19:10<00:00, 30.65s/it]\n"
     ]
    }
   ],
   "source": [
    "#prepare a LIMITED tokenizer for reviews on training data\n",
    "tokenizer_description = Tokenizer(num_words=tot_cnt-cnt) \n",
    "\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    descriptions = [i['description'] for i in listJSON  ]\n",
    "    tokenizer_description.fit_on_texts(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22956c7",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad8c5c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [02:35<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "#x_tokenizer.fit_on_texts(_____)\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    abstracts = [i['abstract'] for i in listJSON  ]#listJSON[:]['description']\n",
    "    x_tokenizer.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f94ce60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 68948/68948 [00:00<00:00, 380128.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 47.82009630446134 %\n",
      "Total Coverage of rare words: 0.2959113934193723 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in tqdm(x_tokenizer.word_counts.items()):\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    \n",
    "    if(value<thresh):\n",
    "        \n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100,\"%\")\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e26fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [02:40<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "#prepare a LIMITED tokenizer for reviews on training label\n",
    "tokenizer_abstract = Tokenizer(num_words=tot_cnt-cnt) \n",
    "\n",
    "\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names))) : \n",
    "    file_name=file_names[i]\n",
    "    listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name)\n",
    "\n",
    "    abstracts = [i['abstract'] for i in listJSON  ]\n",
    "    tokenizer_abstract.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ddebd",
   "metadata": {},
   "source": [
    "## Save des token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44d76ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenize_file(path,filename,JSONlist,tokenizer_x,tokenizer_y):\n",
    "    \n",
    "    if os.path.exists(path+'new_tok_'+filename+'.txt')==True:\n",
    "        os.remove(path+'new_tok_'+filename)\n",
    "        \n",
    "    descriptions = [i['description'] for i in JSONlist  ]\n",
    "    x_tr_seq   =  tokenizer_x.texts_to_sequences(descriptions)\n",
    "    \n",
    "    \n",
    "    \n",
    "    abstracts = [i['abstract'] for i in JSONlist  ]\n",
    "    y_tr_seq   =  tokenizer_y.texts_to_sequences(abstracts) \n",
    "    \n",
    "    #print(len(x_tr_seq))\n",
    "    #print(x_tr_seq)\n",
    "    \n",
    "    new_f= open(path+'new_tok'+filename,'a')\n",
    "  \n",
    "    for i in range(len(JSONlist)) :\n",
    "        #JSONlist[i]['abstract']=x_tr_seq[i]\n",
    "        #JSONlist[i]['description']=y_tr_seq[i]\n",
    "    \n",
    "        updatedJSON={\"publication_number\":JSONlist[i]['publication_number'],\"abstract\":x_tr_seq[i],\"description\":y_tr_seq[i]}\n",
    "        new_f.write(json.dumps(updatedJSON))\n",
    "        \n",
    "        \n",
    "    #print(\"Wrote file \"+new_f.name)\n",
    "    new_f.close()\n",
    "    \n",
    "    #f2= open(path+'new_tok'+filename,'r')\n",
    "    #text = f2.read().replace('}{\"publication_number\"','}\\n{\"publication_number\"').encode(\"utf8\")\n",
    "    \n",
    "    #f2.write(str(text))\n",
    "    #f2.close()\n",
    "    \n",
    "def addLineReturn(path,filename):\n",
    "    f=open(os.path.join(path,file_name2),'r')\n",
    "    text = f.read().replace('}{\"publication_number\"','}\\n{\"publication_number\"').encode(\"utf8\")\n",
    "    f.close()\n",
    "    f2=open(os.path.join(os.path.join(\"data\",kind_data,\"g\"),file_name2),'wb')\n",
    "    f2.write(text)\n",
    "    f2.close()\n",
    "    print(\"Updated file \"+f2.name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43113c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [18:10<00:00,  7.04s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [01:00<00:00,  2.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [00:55<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Enregistrement des données tokénisés\n",
    "os.makedirs(\"data_token\", exist_ok=True)\n",
    "for kind_data in [\"train\",\"val\",\"test\"]:\n",
    "    name_folder0 = \"data_token/\"+kind_data\n",
    "    name_folder = \"data_token/\"+kind_data+\"/g\"\n",
    "    os.makedirs(name_folder0, exist_ok=True)\n",
    "    os.makedirs(name_folder, exist_ok=True)\n",
    "    \n",
    "    file_names = [file for file in os.listdir(os.path.join(\"data\",kind_data,\"g\")) if \".txt\" in file]\n",
    "    for i in tqdm(range(len(file_names))) :\n",
    "        file_name=file_names[i]\n",
    "        listJSON = readData(os.path.join(\"data\",kind_data,\"g\"),file_name) \n",
    "\n",
    "        \n",
    "        \n",
    "        #Padding ?????????????????????????????????????\n",
    "        #x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "        #x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "    \n",
    "        #on save ici le fichier à l'adresse\n",
    "        create_tokenize_file(name_folder+\"/\",file_name,listJSON,tokenizer_description,tokenizer_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c621db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SAVE LES TOKENIZER\n",
    "##MEME TOKENIZER POUR X ET Y ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc39e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:07<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3867\n",
      "481\n",
      "[44, 1160, 40074, 1528, 1821, 7, 867, 303, 1078, 9, 151, 170, 900, 52, 21, 26, 441, 565, 31, 31, 25, 35, 167, 35, 82, 31, 2, 84, 1621, 2361, 3589, 88805, 1887, 1438, 1158, 21, 185, 63696, 2855, 174401, 278, 544, 104, 380, 84, 12517, 1530, 12517, 1530, 167, 6, 35, 82, 121, 380, 84, 170, 900, 170, 900, 2155, 82, 31, 25, 35, 82, 1530, 595, 1096, 5254, 900, 1743, 1814, 28, 1466, 132, 489, 6, 51, 31, 25, 35, 167, 88, 1814, 28, 1466, 132, 2584, 278, 1044, 47, 31, 62, 489, 222, 31, 25, 35, 519, 1044, 278, 25, 900, 519, 136, 278, 17, 808, 1466, 132, 123, 2889, 222, 25, 35, 1466, 132, 583, 104, 278, 1044, 47, 31, 2889, 222, 1031, 867, 1160, 2889, 222, 51, 1466, 132, 25, 35, 293, 121, 28, 1466, 132, 28, 121, 1466, 132, 163, 586, 28, 28, 35, 121, 1466, 132, 1466, 132, 1519, 2889, 222, 4, 2490, 5528, 15210, 847, 1577, 2889, 222, 1189, 222, 2, 762, 1088, 1375, 422, 6094, 222, 7278, 1015, 970, 2, 1541, 147, 4941, 31, 544, 104, 278, 166, 501, 7, 1151, 19970, 508, 3727, 128, 41, 31, 334, 314, 111, 163, 586, 28, 28, 35, 2, 15, 586, 80, 31, 112, 163, 586, 28, 121, 1466, 132, 1015, 970, 5545, 544, 678, 63, 80, 11712, 2158, 18, 544, 104, 278, 166, 82, 1530, 121, 1466, 132, 35, 82, 25, 35, 31, 3702, 228, 544, 2, 157, 3578, 82, 117, 41, 3600, 157, 508, 48, 157, 629, 603, 3793, 144, 470, 82, 48, 157, 629, 603, 144, 144, 52, 31, 35, 337, 31, 489, 6, 4169, 62, 508, 128, 31, 2857, 25, 1466, 132, 51, 201, 3578, 82, 351, 489, 6, 31, 3634, 434, 104, 278, 583, 3578, 82, 117, 470, 117, 157, 1407, 508, 48, 157, 629, 603, 3793, 144, 31, 2465, 155, 508, 278, 294, 252, 503, 3578, 117, 41, 6981, 24, 339, 1335, 159, 278, 939, 511, 339, 2306, 31, 20, 1752, 361, 73, 315, 160, 6981, 134, 1208, 339, 544, 277, 461, 278, 2, 205, 2465, 312, 511, 1528, 2410, 2229, 95, 7, 167, 2889, 489, 222, 583, 104, 278, 1044, 47, 31, 1015, 1388, 104, 278, 2792, 60, 199, 51, 1151, 19970, 508, 3727, 128, 31, 41, 1015, 1388, 51, 7426, 544, 31, 80, 11712, 2158, 18, 104, 278, 166, 3578, 82, 117, 508, 31, 128, 2857, 104, 82, 3578, 231, 31, 3634, 906, 104, 278, 3578, 117, 41, 339, 1335, 159, 278, 939, 511, 1444, 670, 4231, 1335, 169, 31, 2992, 418, 990, 2992, 1321, 849, 1528, 1821, 24, 25984, 328, 762, 1088, 35, 82, 334, 314, 111, 1812, 2959, 2204, 8544, 422, 82, 1049, 38, 1053, 340, 2347, 347, 159, 10, 7, 114, 24, 338, 4746, 334, 7, 202, 1278, 96, 289, 2, 19, 89, 384, 487, 537, 139, 760, 745, 234, 7, 334, 314, 111]\n",
      "1649\n",
      "1649\n"
     ]
    }
   ],
   "source": [
    "###### Du test\n",
    "file_names = [file for file in os.listdir(os.path.join(\"data\",\"train\",\"g\")) if \".txt\" in file]\n",
    "for i in tqdm(range(len(file_names[0]))) : \n",
    "    file_name=file_names[i]\n",
    "\n",
    "    listJSON = readData(os.path.join(\"data\",\"train\",\"g\"),file_name)\n",
    "    descriptions = [i['description'] for i in listJSON  ]\n",
    "    abstracts = [i['abstract'] for i in listJSON  ]\n",
    "\n",
    "\n",
    "x_tr_seq   =  tokenizer_description.texts_to_sequences(descriptions)\n",
    "\n",
    "print(len(descriptions[0]))\n",
    "print(len(x_tr_seq[0]))\n",
    "print(x_tr_seq[0])\n",
    "\n",
    "print(len(x_tr_seq))\n",
    "print(len(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "711154db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(tokenizer_description.get_config())\n",
    "print(tokenizer_abstract.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab31ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "878f6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enregistrement du tokenizer\n",
    "path = \"data_token/\"\n",
    "\n",
    "Json_tok_ab = tokenizer_abstract.to_json()\n",
    "new_f_ab = open(path+'tokenizer_abstract.txt','a')\n",
    "new_f_ab.write(json.dumps(Json_tok_ab))\n",
    "new_f_ab.close()\n",
    "\n",
    "Json_tok_de = tokenizer_description.to_json()\n",
    "new_f_de = open(path+'tokenizer_description.txt','a')\n",
    "new_f_de.write(json.dumps(Json_tok_ab))\n",
    "new_f_de.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b625ef4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c2688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28260877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc83ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7ac56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509ecb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfece6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(len(JSONlist)) :\n",
    "        abstract = JSONlist[i]['abstract']\n",
    "        description = JSONlist[i]['description']\n",
    "            \n",
    "        abstract1 = abstract.lower()\n",
    "        description1 = description.lower()\n",
    "            \n",
    "        abstract2 = re.sub('[^a-zA-Z ]',' ',abstract1)\n",
    "        description2 = re.sub('[^a-zA-Z ]',' ',description1)\n",
    "            \n",
    "        abstract3 = re.sub(r'(?:^| )\\w(?:$| )', ' ', abstract2).strip()\n",
    "        description3 = re.sub(r'(?:^| )\\w(?:$| )', ' ', description2).strip()\n",
    "            \n",
    "        abstract4 = ' '.join([word for word in abstract3.split() if word not in cachedstopwords])\n",
    "        description4 = ' '.join([word for word in description3.split() if word not in cachedstopwords])\n",
    "            \n",
    "        abstract5=re.sub(' +',' ',abstract4)\n",
    "        description5=re.sub(' +',' ',description4)\n",
    "            \n",
    "        JSONlist[i]['abstract']=abstract5\n",
    "        JSONlist[i]['description']=description5\n",
    "        updatedJSON={\"publication_number\":JSONlist[i]['publication_number'],\"abstract\":abstract5,\"description\":description5}\n",
    "        new_f.write(json.dumps(updatedJSON))\n",
    "    print(\"Wrote file \"+new_f.name)\n",
    "    new_f.close()\n",
    "    return JSONlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bde9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1799e4ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f1867f5fdb64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#prepare a tokenizer for reviews on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_tr' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(x_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86c620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "sj_train_features_scaled = sj_train_features.copy()\n",
    "\n",
    "\n",
    "sj_train_features_scaled[sj_train_features_scaled.columns]= scaler.fit_transform(sj_train_features[sj_train_features.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_features_scaled['total_cases'] = sj_train_features['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab483aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized_torch = []\n",
    "for column in sj_train_features_scaled.columns:\n",
    "    train_data_normalized_torch.append(torch.FloatTensor(sj_train_features_scaled[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a95d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On test en selectionnant un certain nombre de features\n",
    "\n",
    "features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c','total_cases']\n",
    "\n",
    "train_data_selected_torch = [torch.FloatTensor(sj_train_features_scaled[feature]) for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw): #remplacer lim-1 par 20 si ça bug\n",
    "    inout_seq = []\n",
    "    L = len(input_data[0])\n",
    "    lim = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[0][i:i+tw].view(tw,1,-1)\n",
    "        for j in range(1,lim-1):\n",
    "            train_seq = torch.cat((train_seq,input_data[j][i:i+tw].view(tw,1,-1)),-1)\n",
    "\n",
    "        train_label = input_data[lim-1][i+tw]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "inout_seq = create_inout_sequences(train_data_normalized_torch, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inout_seq_selected = create_inout_sequences(train_data_selected_torch, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0969d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393fcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden_layer_size=150, output_size=1): #hidden_layer_size = 100\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq, self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out)\n",
    "        return predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "training_ratio = 0.8\n",
    "training_data = inout_seq[0:math.floor(training_ratio*len(inout_seq))]\n",
    "valid_data = inout_seq[math.floor(training_ratio*len(inout_seq)):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4080a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(inout_seq):\n",
    "    train_chouchou = [inout_seq[i] for i in train_index]\n",
    "    train_chouchou = [inout_seq[i] for i in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc78532",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "training_loss=[]\n",
    "valid_loss=[]\n",
    "for train_index, test_index in kf.split(inout_seq):\n",
    "    training_data = [inout_seq[i] for i in train_index]\n",
    "    valid_data = [inout_seq[i] for i in test_index]\n",
    "    for i in range(epochs):\n",
    "        if i == 100:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for seq, labels in training_data:\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "            single_loss_r = loss_function(y_pred[0][0], labels)\n",
    "            single_loss_r.backward()\n",
    "            training_loss.append(single_loss_r.item())\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        for seq, labels in valid_data:\n",
    "            y_pred = model(seq)\n",
    "            running_loss = loss_function(y_pred[0][0], labels)\n",
    "            valid_loss.append(running_loss.item())\n",
    "\n",
    "        print(\"Epoch: \",i, \"__ Training Loss: \", training_loss[-1],\"__ Valid Loss:\", valid_loss[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b172d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea2819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
